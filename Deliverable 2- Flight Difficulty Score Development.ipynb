{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8625f3b-e83d-41cb-a59b-5840a74eb60c",
   "metadata": {},
   "source": [
    "# DELIVERABLE 2: FLIGHT DIFFICULTY SCORE DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2666ce-4f1d-4d75-a985-0dfcb259b7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cfe46b1-3e56-443b-ad67-4b6218a6c4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "flight_df = pd.read_csv('Flight Level Data.csv')\n",
    "bags_df = pd.read_csv('Bag+Level+Data.csv')\n",
    "pnr_flight_df = pd.read_csv('PNR+Flight+Level+Data.csv')\n",
    "pnr_remarks_df = pd.read_csv('PNR Remark Level Data.csv')\n",
    "airports_df = pd.read_csv('Airports Data.csv')\n",
    "print(\"All CSV files loaded successfully!\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba00fd-22ff-4ce9-b690-d7dff0dfa913",
   "metadata": {},
   "source": [
    "# Data Merging and Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "719bd3b6-e397-4eae-b949-55fd2cdb979b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master DataFrame created successfully.\n",
      "Shape of master_df: (8063, 22)\n"
     ]
    }
   ],
   "source": [
    "# This cell contains the logic to merge and clean all data into a single master DataFrame.\n",
    "\n",
    "#  1. Clean and Prepare Primary DataFrame \n",
    "flight_df.columns = flight_df.columns.str.lower().str.strip()\n",
    "for col in ['scheduled_departure_datetime_local', 'scheduled_arrival_datetime_local', 'actual_departure_datetime_local', 'actual_arrival_datetime_local', 'scheduled_departure_date_local']:\n",
    "    flight_df[col] = pd.to_datetime(flight_df[col], errors='coerce')\n",
    "flight_df.drop_duplicates(subset=['company_id', 'flight_number', 'scheduled_departure_date_local'], inplace=True)\n",
    "flight_df.dropna(subset=['actual_departure_datetime_local'], inplace=True)\n",
    "\n",
    "# 2. Prepare and Aggregate Secondary DataFrames \n",
    "pnr_flight_df.columns = pnr_flight_df.columns.str.lower().str.strip()\n",
    "pnr_flight_df['scheduled_departure_date_local'] = pd.to_datetime(pnr_flight_df['scheduled_departure_date_local'], errors='coerce')\n",
    "bags_df.columns = bags_df.columns.str.lower().str.strip()\n",
    "bags_df['scheduled_departure_date_local'] = pd.to_datetime(bags_df['scheduled_departure_date_local'], errors='coerce')\n",
    "pnr_remarks_df.columns = pnr_remarks_df.columns.str.lower().str.strip()\n",
    "\n",
    "# Aggregate Passenger data\n",
    "pax_per_pnr = pnr_flight_df.drop_duplicates(subset=['record_locator', 'flight_number', 'scheduled_departure_date_local'])\n",
    "pax_agg = pax_per_pnr.groupby(['company_id', 'flight_number', 'scheduled_departure_date_local']).agg(\n",
    "    total_pax=('total_pax', 'sum'),\n",
    "    child_pax_count=('is_child', lambda x: (x == 'Y').sum()),\n",
    "    lap_child_count=('lap_child_count', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Aggregate Bag data\n",
    "bag_agg = bags_df.groupby(['company_id', 'flight_number', 'scheduled_departure_date_local']).agg(\n",
    "    total_bags=('bag_tag_unique_number', 'count'),\n",
    "    transfer_bags=('bag_type', lambda x: x.isin(['Transfer', 'Hot']).sum()),\n",
    "    hot_transfer_bags=('bag_type', lambda x: (x == 'Hot').sum())\n",
    ").reset_index()\n",
    "\n",
    "# Aggregate SSR data\n",
    "pnr_with_date = pnr_flight_df[['record_locator', 'company_id', 'flight_number', 'scheduled_departure_date_local']].drop_duplicates()\n",
    "remarks_to_merge = pnr_remarks_df.drop(columns=['flight_number', 'pnr_creation_date'])\n",
    "remarks_with_date = pd.merge(remarks_to_merge, pnr_with_date, on='record_locator', how='left')\n",
    "ssr_agg = remarks_with_date.groupby(['company_id', 'flight_number', 'scheduled_departure_date_local']).size().reset_index(name='ssr_count')\n",
    "\n",
    "#  3. Merge into Master DataFrame \n",
    "master_df = pd.merge(flight_df, pax_agg, on=['company_id', 'flight_number', 'scheduled_departure_date_local'], how='left')\n",
    "master_df = pd.merge(master_df, bag_agg, on=['company_id', 'flight_number', 'scheduled_departure_date_local'], how='left')\n",
    "master_df = pd.merge(master_df, ssr_agg, on=['company_id', 'flight_number', 'scheduled_departure_date_local'], how='left')\n",
    "\n",
    "#  4. Final Cleaning \n",
    "cols_to_fill = ['total_pax', 'child_pax_count', 'lap_child_count', 'total_bags', 'transfer_bags', 'hot_transfer_bags', 'ssr_count']\n",
    "for col in cols_to_fill:\n",
    "    master_df[col] = master_df[col].fillna(0)\n",
    "\n",
    "print(\"Master DataFrame created successfully.\")\n",
    "print(f\"Shape of master_df: {master_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db35ad3-ac4f-493b-a4f7-a85107f31313",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8981068b-178f-498b-9eca-f6186d4b3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features.\n",
      "Feature engineering complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Engineering features.\")\n",
    "\n",
    "#  Feature Category: Ground Time Constraints \n",
    "master_df['f_ground_time_pressure'] = master_df['minimum_turn_minutes'] / master_df['scheduled_ground_time_minutes']\n",
    "\n",
    "#  Feature Category: Flight-Specific Characteristics\n",
    "# 1. Passenger Load\n",
    "master_df['f_load_factor'] = master_df['total_pax'] / master_df['total_seats']\n",
    "# 2. Children on board\n",
    "master_df['f_child_ratio'] = (master_df['child_pax_count'] + master_df['lap_child_count']) / master_df['total_pax']\n",
    "# 3. Baggage Load\n",
    "master_df['f_bags_per_pax'] = master_df['total_bags'] / master_df['total_pax']\n",
    "# 4. Baggage Complexity (Transfer bags are harder to handle)\n",
    "master_df['f_transfer_bag_ratio'] = master_df['transfer_bags'] / master_df['total_bags']\n",
    "# 5. Aircraft Size (Wide-body planes require more resources)\n",
    "wide_bodies = ['B767', 'B777', 'B787', 'A330', 'A340', 'A350', 'A380']\n",
    "master_df['f_is_wide_body'] = master_df['fleet_type'].apply(lambda x: 1 if any(wb in str(x) for wb in wide_bodies) else 0)\n",
    "# 6. Haul (Longer flights can have more complex catering, cargo, and crew needs)\n",
    "master_df['flight_duration_hours'] = (master_df['scheduled_arrival_datetime_local'] - master_df['scheduled_departure_datetime_local']).dt.total_seconds() / 3600\n",
    "haul_bins = [-1, 3, 6, 24] # up to 3h=Short, 3-6h=Medium, >6h=Long\n",
    "haul_labels = [0, 1, 2] # Numerical representation for the model\n",
    "master_df['f_haul_category'] = pd.cut(master_df['flight_duration_hours'], bins=haul_bins, labels=haul_labels, right=True)\n",
    "\n",
    "#  Feature Category: Passenger Service Needs \n",
    "# 1. SSRs \n",
    "master_df.rename(columns={'ssr_count': 'f_ssr_count'}, inplace=True)\n",
    "# 2. Hot bags indicate tight connections, a proxy for passenger connection stress\n",
    "master_df.rename(columns={'hot_transfer_bags': 'f_hot_transfer_bags'}, inplace=True)\n",
    "\n",
    "# Additional Features\n",
    "# 1. Departure Time (Morning/Afternoon/Evening rush hours are more complex)\n",
    "master_df['f_departure_hour'] = master_df['scheduled_departure_datetime_local'].dt.hour\n",
    "# 2. International flights have extra documentation/security requirements\n",
    "airports_df.columns = airports_df.columns.str.lower().str.strip()\n",
    "master_df = pd.merge(master_df, airports_df, left_on='scheduled_arrival_station_code', right_on='airport_iata_code', how='left')\n",
    "master_df['f_is_international'] = (master_df['iso_country_code'] != 'US').astype(int)\n",
    "\n",
    "# Final Cleanup \n",
    "# Clean up any NaNs or Infs created during division\n",
    "feature_cols_to_clean = [\n",
    "    'f_ground_time_pressure', 'f_load_factor', 'f_child_ratio', 'f_bags_per_pax',\n",
    "    'f_transfer_bag_ratio'\n",
    "]\n",
    "master_df[feature_cols_to_clean] = master_df[feature_cols_to_clean].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "master_df['f_haul_category'] = master_df['f_haul_category'].cat.codes # Convert categorical to numeric\n",
    "\n",
    "print(\"Feature engineering complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b066841-7d84-4029-af2d-1a7f1a17e772",
   "metadata": {},
   "source": [
    "# Scoring, Ranking, and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc0cac6e-25ef-4adb-850e-1ae7cd9963f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight Difficulty Score calculated, ranked, and classified.\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Feature Set and Weights \n",
    "feature_cols = [\n",
    "    'f_ground_time_pressure', 'f_transfer_bag_ratio', 'f_ssr_count', 'f_load_factor',\n",
    "    'f_is_wide_body', 'f_bags_per_pax', 'f_haul_category', 'f_is_international',\n",
    "    'f_hot_transfer_bags', 'f_child_ratio'\n",
    "]\n",
    "weights = {\n",
    "    'f_ground_time_pressure': 0.25, 'f_transfer_bag_ratio': 0.20, 'f_ssr_count': 0.15,\n",
    "    'f_load_factor': 0.10, 'f_is_wide_body': 0.07, 'f_bags_per_pax': 0.05,\n",
    "    'f_haul_category': 0.05, 'f_is_international': 0.05, 'f_hot_transfer_bags': 0.05,\n",
    "    'f_child_ratio': 0.03\n",
    "}\n",
    "\n",
    "# 2. Calculate Scores Day by Day \n",
    "all_days_scored = []\n",
    "for date, daily_df in master_df.groupby(master_df['scheduled_departure_date_local'].dt.date):\n",
    "    daily_df_processed = daily_df.copy()\n",
    "    for col in feature_cols:\n",
    "        if daily_df_processed[col].max() == daily_df_processed[col].min():\n",
    "            daily_df_processed[f'{col}_norm'] = 0.0\n",
    "        else:\n",
    "            scaler = MinMaxScaler()\n",
    "            daily_df_processed[f'{col}_norm'] = scaler.fit_transform(daily_df_processed[[col]])\n",
    "\n",
    "    daily_df_processed['difficulty_score'] = 0\n",
    "    for feature, weight in weights.items():\n",
    "        daily_df_processed['difficulty_score'] += daily_df_processed[f'{feature}_norm'] * weight\n",
    "    all_days_scored.append(daily_df_processed)\n",
    "\n",
    "scored_df = pd.concat(all_days_scored)\n",
    "\n",
    "# 3. Final Ranking & Classification \n",
    "scored_df['difficulty_score'] = (MinMaxScaler(feature_range=(1, 100)).fit_transform(scored_df[['difficulty_score']]))\n",
    "scored_df['daily_rank'] = scored_df.groupby(scored_df['scheduled_departure_date_local'].dt.date)['difficulty_score'].rank(method='first', ascending=False)\n",
    "\n",
    "def classify_flight(rank, total_flights):\n",
    "    if rank <= total_flights * 0.2: return 'Difficult'\n",
    "    elif rank <= total_flights * 0.7: return 'Medium'\n",
    "    else: return 'Easy'\n",
    "\n",
    "group_sizes = scored_df.groupby(scored_df['scheduled_departure_date_local'].dt.date)['daily_rank'].transform('max')\n",
    "scored_df['difficulty_class'] = scored_df.apply(lambda row: classify_flight(row['daily_rank'], group_sizes[row.name]), axis=1)\n",
    "\n",
    "print(\"Flight Difficulty Score calculated, ranked, and classified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada70d7-6b91-4e12-8e5d-f74bcf229441",
   "metadata": {},
   "source": [
    "# Review and Save Final Output for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8f0e7be-b113-46e2-88cb-e707602fb9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------\n",
      "SUCCESS: Your submission file has been generated!\n",
      "Filename: test_Hacks_on_Crack.csv\n",
      "----------------------------------------------------\n",
      "\n",
      "File Preview (First 5 Rows):\n",
      "   company_id  flight_number scheduled_departure_date_local  \\\n",
      "35         OO           5564                     2025-08-01   \n",
      "42         UA           1899                     2025-08-01   \n",
      "48         UA           2189                     2025-08-01   \n",
      "69         G7           4590                     2025-08-01   \n",
      "76         UA            224                     2025-08-01   \n",
      "\n",
      "   scheduled_departure_station_code scheduled_arrival_station_code fleet_type  \\\n",
      "35                              ORD                            SBN    CRJ-550   \n",
      "42                              ORD                            YYC   A319-100   \n",
      "48                              ORD                            LGA  B737-MAX8   \n",
      "69                              ORD                            MDT    CRJ-550   \n",
      "76                              ORD                            BZN   B737-800   \n",
      "\n",
      "    f_ground_time_pressure  f_transfer_bag_ratio  f_ssr_count  f_load_factor  \\\n",
      "35                0.508772              0.916667          0.0       0.940000   \n",
      "42                0.742857              0.404494         12.0       1.007937   \n",
      "48                0.625000              0.079365          2.0       1.000000   \n",
      "69                0.690476              0.730769          2.0       0.980000   \n",
      "76                0.291262              0.403101          6.0       0.969880   \n",
      "\n",
      "    f_is_wide_body  f_bags_per_pax  f_haul_category  f_is_international  \\\n",
      "35               0        0.765957                0                   0   \n",
      "42               0        0.700787                0                   1   \n",
      "48               0        0.379518                1                   0   \n",
      "69               0        0.530612                1                   0   \n",
      "76               0        0.801242                0                   0   \n",
      "\n",
      "    f_hot_transfer_bags  f_child_ratio  difficulty_score  daily_rank  \\\n",
      "35                    0       0.021277         44.306069        93.0   \n",
      "42                    0       0.031496         44.067834        99.0   \n",
      "48                    0       0.018072         22.281315       542.0   \n",
      "69                    0       0.040816         42.997542       126.0   \n",
      "76                    0       0.024845         32.547694       393.0   \n",
      "\n",
      "   difficulty_class  \n",
      "35        Difficult  \n",
      "42        Difficult  \n",
      "48             Easy  \n",
      "69           Medium  \n",
      "76             Easy  \n"
     ]
    }
   ],
   "source": [
    "group_name = \"Hacks_on_Crack\"  \n",
    "\n",
    "# --- 2. Select Columns for Final Output as per Submission Guidelines ---\n",
    "flight_details_cols = [\n",
    "    'company_id', 'flight_number', 'scheduled_departure_date_local',\n",
    "    'scheduled_departure_station_code', 'scheduled_arrival_station_code', 'fleet_type'\n",
    "]\n",
    "score_cols = ['difficulty_score', 'daily_rank', 'difficulty_class']\n",
    "final_output_df = scored_df[flight_details_cols + feature_cols + score_cols]\n",
    "\n",
    "# --- 3. Save to CSV in the Required Format ---\n",
    "output_filename = f\"test_{group_name}.csv\"\n",
    "final_output_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(\"\\n----------------------------------------------------\")\n",
    "print(f\"SUCCESS: Your submission file has been generated!\")\n",
    "print(f\"Filename: {output_filename}\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"\\nFile Preview (First 5 Rows):\")\n",
    "print(final_output_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725287a2-507d-453c-8f85-7535ca2a407e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
